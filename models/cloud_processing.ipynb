{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing Example\n",
    "This notebook demonstrates how to use the CloudProcessor for batch processing data with single or multiple workers.\n",
    "\n",
    "## 1. Configuration\n",
    "Set the project root path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "def setup_project_path():\n",
    "    \"\"\"Add project root to Python path by searching for .git directory\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Search up the directory tree for .git folder or pyproject.toml\n",
    "    root_indicators = ['.git', 'pyproject.toml']\n",
    "    \n",
    "    while current_path != current_path.parent:\n",
    "        if any((current_path / indicator).exists() for indicator in root_indicators):\n",
    "            sys.path.append(str(current_path))\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root. \"\n",
    "        \"Please run this notebook from within the project directory.\"\n",
    "    )\n",
    "\n",
    "# Setup path\n",
    "project_root = setup_project_path()\n",
    "print(f\"Project root detected at: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your vertex ai configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vertex_ai import CloudProcessor, MachineConfig, JobConfig, get_config\n",
    "\n",
    "# Get vertex ai configuration for 'dev' environment\n",
    "config = get_config(\"dev\")\n",
    "\n",
    "# Initialize the processor with both the staging and data bucket\n",
    "processor = CloudProcessor(\n",
    "    project_id=config.project_id,\n",
    "    location=config.region,\n",
    "    staging_bucket=f\"{config.project_id}-{config.environment}-staging\",\n",
    "    data_bucket=f\"{config.project_id}-{config.environment}-data\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Processing Function\n",
    "First, let's define a sample processing function that will be executed on each worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_function = \"\"\"\n",
    "def process_single_video(input_path: str, temp_dir: str) -> str:\n",
    "    '''Sample processing function that simulates video processing.\n",
    "    In practice, replace this with your actual processing logic.'''\n",
    "    import time\n",
    "    import os\n",
    "    \n",
    "    # Simulate processing time\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Create a dummy output file\n",
    "    output_path = os.path.join(temp_dir, 'processed_' + os.path.basename(input_path))\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('Processed content')\n",
    "    \n",
    "    return output_path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Worker Example\n",
    "Process all files sequentially with a single worker using a given batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure machine resources\n",
    "machine_config = MachineConfig(\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    disk_size_gb=100\n",
    ")\n",
    "\n",
    "# Configure job parameters\n",
    "job_config = JobConfig(\n",
    "    provisioning_model=\"SPOT\",   # \"SPOT\" means the job will run on preemptible instances, which are cheaper but may be interrupted at any time. For time critical jobs you may use \"DEDICATED\"\n",
    "    restart_on_failure=True,\n",
    "    timeout_days=1.0\n",
    ")\n",
    "\n",
    "# Submit single-worker job\n",
    "single_worker_job = processor.submit_job(\n",
    "    processing_fn=processing_function,\n",
    "    input_folder=\"raw-data/\",  # Folder for input\n",
    "    output_folder=\"landmarks/\",  # Folder for output\n",
    "    job_config=job_config,\n",
    "    batch_size=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Workers Example\n",
    "Process files in parallel using multiple workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Configure GPU for faster processing\n",
    "gpu_machine_config = MachineConfig(\n",
    "    machine_type=\"n1-standard-8\",\n",
    "    disk_size_gb=200\n",
    ")\n",
    "\n",
    "# Configure job to use spot instances for cost savings\n",
    "spot_job_config = JobConfig(\n",
    "    provisioning_model=\"SPOT\",\n",
    "    restart_on_failure=True,\n",
    "    timeout_days=2.0\n",
    ")\n",
    "\n",
    "# For multi-worker job with custom buckets\n",
    "multi_worker_job = processor.submit_job(\n",
    "    processing_fn=processing_function,\n",
    "    input_folder=\"raw-data/\",\n",
    "    output_folder=\"landmarks/\",\n",
    "    input_bucket=\"custom-input-bucket\",  # Optional override\n",
    "    output_bucket=\"custom-output-bucket\", # Optional override\n",
    "    workers=4,\n",
    "    machine_config=gpu_machine_config,\n",
    "    job_config=spot_job_config,\n",
    "    batch_size=5\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
