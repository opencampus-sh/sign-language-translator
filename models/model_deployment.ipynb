{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Model Deployment to Vertex AI\n",
    "\n",
    "This notebook guides you through deploying a Hugging Face model to Vertex AI. It covers:\n",
    "1. Setting up your environment\n",
    "2. Downloading and packaging your model\n",
    "3. Building and pushing the Docker container\n",
    "4. Deploying to Vertex AI\n",
    "\n",
    "It uses environment variables that should be set from your infrastructure configuration provivded under `models/config/`.\n",
    "\n",
    "Required environment variables:\n",
    "```\n",
    "GCP_PROJECT_ID            # Your GCP project ID\n",
    "GCP_REGION               # Your GCP region\n",
    "GCP_ARTIFACT_REGISTRY    # Artifact Registry repository\n",
    "MODEL_ARTIFACTS_BUCKET   # GCS bucket for model artifacts\n",
    "VERTEX_AI_ENDPOINT       # Vertex AI endpoint name\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "- Google Cloud SDK installed and configured\n",
    "- Docker installed and running\n",
    "- Required Python packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install google-cloud-aiplatform huggingface-hub transformers torch google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Set the project root path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root detected at: /home/steffen/sign-language-translator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "def setup_project_path():\n",
    "    \"\"\"Add project root to Python path by searching for .git directory\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Search up the directory tree for .git folder or pyproject.toml\n",
    "    root_indicators = ['.git', 'pyproject.toml']\n",
    "    \n",
    "    while current_path != current_path.parent:\n",
    "        if any((current_path / indicator).exists() for indicator in root_indicators):\n",
    "            sys.path.append(str(current_path))\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root. \"\n",
    "        \"Please run this notebook from within the project directory.\"\n",
    "    )\n",
    "\n",
    "# Setup path\n",
    "project_root = setup_project_path()\n",
    "print(f\"Project root detected at: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your project configuration and model details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env\n",
      "Loading configuration from /home/steffen/sign-language-translator/models/vertex_ai/config/dev.yaml\n",
      "Configuration loaded successfully!\n",
      "\n",
      "Environment settings:\n",
      "{\n",
      "  \"environment\": \"dev\",\n",
      "  \"project_id\": \"sign-lang-translator-20241029\",\n",
      "  \"region\": \"europe-west3\",\n",
      "  \"artifact_registry_repo\": \"dev-vertex-ai-repo\",\n",
      "  \"artifacts_bucket\": \"sign-lang-translator-20241029-dev-vertex-ai-artifacts\",\n",
      "  \"endpoint_name\": \"vertex-ai\",\n",
      "  \"model_id\": \"openai/whisper-small\",\n",
      "  \"image_name\": \"untrained-predictor\",\n",
      "  \"model_version\": \"v1\",\n",
      "  \"hf_task\": \"text-to-speech\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict\n",
    "from models.vertex_ai import get_config\n",
    "\n",
    "# Model-specific configuration that might change between deployments\n",
    "model_config = {\n",
    "    'model_id': 'openai/whisper-small',  # Hugging Face model ID\n",
    "    'image_name': 'untrained-predictor',           # Docker image name\n",
    "    'model_version': 'v1',                  # Model version\n",
    "    'hf_task': 'text-to-speech',  # Hugging Face task type\n",
    "}\n",
    "\n",
    "# Load environment configuration\n",
    "try:\n",
    "    vertex_ai_config = get_config(\"dev\") # Get vertex ai configuration for 'dev' environment\n",
    "    \n",
    "    # Access config properties directly\n",
    "    config = {\n",
    "        'environment': vertex_ai_config.environment,\n",
    "        'project_id': vertex_ai_config.project_id,\n",
    "        'region': vertex_ai_config.region,\n",
    "        'artifact_registry_repo': vertex_ai_config.environment + '-' + vertex_ai_config.endpoint_name + '-repo',\n",
    "        'artifacts_bucket': vertex_ai_config.project_id + '-' + vertex_ai_config.environment + '-' + vertex_ai_config.endpoint_name + '-artifacts',\n",
    "        'endpoint_name': vertex_ai_config.endpoint_name,\n",
    "        **model_config  # Add model-specific config\n",
    "    }\n",
    "    \n",
    "    print(\"Configuration loaded successfully!\")\n",
    "    print(\"\\nEnvironment settings:\")\n",
    "    print(json.dumps(config, indent=2))\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nPlease set the required environment variables before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Package Model\n",
    "Download the model from Hugging Face and package it for Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/steffen/.cache/huggingface/token\n",
      "Login successful\n",
      "Downloading model openai/whisper-small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 23:52:01.587346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-28 23:52:04.389221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./types/huggingface/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steffen/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:388: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tar.gz archive...\n",
      "Uploading to gs://sign-lang-translator-20241029-dev-vertex-ai-artifacts/v1/model.tar.gz\n",
      "\n",
      "Model artifacts uploaded to: gs://sign-lang-translator-20241029-dev-vertex-ai-artifacts/v1/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from google.cloud import storage\n",
    "\n",
    "def download_and_package_model(model_id: str, model_dir: str = './types/huggingface/model', skip_download: bool = False):\n",
    "    \"\"\"Download and package model, or use existing tar.gz if available\"\"\"\n",
    "    tar_path = './types/huggingface/model.tar.gz'\n",
    "    \n",
    "    # If tar.gz exists and skip_download is False, use existing file\n",
    "    if os.path.exists(tar_path) and not skip_download:\n",
    "        print(f\"Using existing {tar_path}\")\n",
    "        return tar_path\n",
    "    \n",
    "    # Otherwise, download and package the model\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading model {model_id}...\")\n",
    "    model = AutoModel.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    print(f\"Saving to {model_dir}\")\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    \n",
    "    print(\"Creating tar.gz archive...\")\n",
    "    with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "        tar.add(model_dir, arcname=\".\")\n",
    "    \n",
    "    return tar_path\n",
    "\n",
    "\n",
    "def upload_to_gcs(file_path: str, bucket_name: str, model_version: str):\n",
    "    from google.api_core import retry\n",
    "    destination_blob_name = f\"{model_version}/model.tar.gz\"\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "    print(f\"Uploading to gs://{bucket_name}/{destination_blob_name}\")\n",
    "    \n",
    "    # Configure retry with longer timeout\n",
    "    retry_config = retry.Retry(\n",
    "        initial=1.0,  # Initial delay in seconds\n",
    "        maximum=60.0,  # Maximum delay between retries\n",
    "        multiplier=2.0,  # Multiplier applied to delay between retries\n",
    "        deadline=600.0  # Total timeout in seconds (10 minutes)\n",
    "    )\n",
    "    \n",
    "    blob.upload_from_filename(\n",
    "        file_path,\n",
    "        retry=retry_config,\n",
    "        timeout=600  # 10 minute timeout\n",
    "    )\n",
    "    \n",
    "    return f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "\n",
    "# Execute\n",
    "if 'HUGGINGFACE_TOKEN' in os.environ:\n",
    "    login(os.environ['HUGGINGFACE_TOKEN'])\n",
    "\n",
    "tar_path = download_and_package_model(config['model_id'], skip_download=True)\n",
    "artifacts_uri = upload_to_gcs(\n",
    "    tar_path, \n",
    "    config['artifacts_bucket'],\n",
    "    config['model_version']\n",
    ")\n",
    "print(f\"\\nModel artifacts uploaded to: {artifacts_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build and Push Docker Container\n",
    "Build the custom prediction routine container and push it to Artifact Registry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Docker authentication...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Your config file at [/home/steffen/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"europe-west3-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: europe-west3-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Docker image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 483B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/alvarobartt/torch-gpu:py310-cu12.3-torch-2.2.0\n",
      "#2 DONE 0.9s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 [1/5] FROM docker.io/alvarobartt/torch-gpu:py310-cu12.3-torch-2.2.0@sha256:1d47d9917362fbfdf5e713a7408f81bdbfd8afb40518a8229c5a953aff991507\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 69B 0.0s done\n",
      "#5 DONE 0.1s\n",
      "\n",
      "#6 [2/5] WORKDIR /app\n",
      "#6 CACHED\n",
      "\n",
      "#7 [3/5] COPY requirements.txt .\n",
      "#7 CACHED\n",
      "\n",
      "#8 [4/5] COPY predictor.py .\n",
      "#8 CACHED\n",
      "\n",
      "#9 [5/5] RUN pip install --no-cache-dir -r requirements.txt     fastapi     \"uvicorn[standard]\"     google-cloud-aiplatform\n",
      "#9 4.792 Collecting fastapi\n",
      "#9 5.108   Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "#9 5.500 Collecting google-cloud-aiplatform\n",
      "#9 5.537   Downloading google_cloud_aiplatform-1.73.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "#9 5.573 Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
      "#9 5.895 Collecting transformers==4.38.1 (from -r requirements.txt (line 2))\n",
      "#9 5.934   Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "#9 6.005      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.1/131.1 kB 2.5 MB/s eta 0:00:00\n",
      "#9 6.167 Collecting accelerate==0.27.0 (from -r requirements.txt (line 3))\n",
      "#9 6.204   Downloading accelerate-0.27.0-py3-none-any.whl.metadata (18 kB)\n",
      "#9 6.418 Collecting uvicorn[standard]\n",
      "#9 6.452   Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "#9 6.630 Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "#9 6.632 Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (4.9.0)\n",
      "#9 6.634 Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (1.12)\n",
      "#9 6.645 Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (3.2.1)\n",
      "#9 6.647 Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (3.1.3)\n",
      "#9 6.648 Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (2024.2.0)\n",
      "#9 6.661 Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "#9 6.669 Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "#9 6.682 Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "#9 6.690 Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (8.9.2.26)\n",
      "#9 6.696 Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "#9 6.709 Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "#9 6.725 Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "#9 6.729 Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "#9 6.741 Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "#9 6.745 Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (2.19.3)\n",
      "#9 6.769 Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (12.1.105)\n",
      "#9 6.769 Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "#9 8.755 Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 8.829   Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "#9 9.893 Collecting numpy>=1.17 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 9.927   Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "#9 9.945      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.0/62.0 kB 6.7 MB/s eta 0:00:00\n",
      "#9 10.17 Collecting packaging>=20.0 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 10.21   Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "#9 10.48 Collecting pyyaml>=5.1 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 10.51   Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "#9 11.81 Collecting regex!=2019.12.17 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 11.85   Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "#9 11.91      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 1.3 MB/s eta 0:00:00\n",
      "#9 12.13 Collecting requests (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 12.19   Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "#9 13.32 Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 13.37   Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "#9 13.92 Collecting safetensors>=0.4.1 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 13.96   Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "#9 14.21 Collecting tqdm>=4.27 (from transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 14.25   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "#9 14.29      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 3.0 MB/s eta 0:00:00\n",
      "#9 14.88 Collecting psutil (from accelerate==0.27.0->-r requirements.txt (line 3))\n",
      "#9 14.92   Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "#9 14.98 Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r requirements.txt (line 1)) (12.3.101)\n",
      "#9 15.22 Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
      "#9 15.26   Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "#9 15.93 Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "#9 15.96   Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "#9 15.99      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.8/170.8 kB 5.6 MB/s eta 0:00:00\n",
      "#9 16.21 Collecting click>=7.0 (from uvicorn[standard])\n",
      "#9 16.27   Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "#9 16.40 Collecting h11>=0.8 (from uvicorn[standard])\n",
      "#9 16.44   Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "#9 16.68 Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
      "#9 16.75   Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "#9 16.86 Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
      "#9 16.91   Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "#9 17.19 Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard])\n",
      "#9 17.24   Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "#9 17.59 Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "#9 17.64   Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "#9 18.13 Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "#9 18.17   Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "#9 19.09 Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "#9 19.12   Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "#9 19.47 Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform)\n",
      "#9 19.51   Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "#9 19.68 Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform)\n",
      "#9 19.72   Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "#9 20.67 Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform)\n",
      "#9 20.71   Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "#9 21.00 Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "#9 21.03   Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "#9 21.35 Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "#9 21.40   Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "#9 21.62 Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "#9 21.66   Downloading google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "#9 22.11 Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "#9 22.15   Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "#9 22.36 Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
      "#9 22.39   Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "#9 22.61 Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "#9 22.65   Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "#9 24.63 Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "#9 24.66   Downloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "#9 24.92 Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "#9 24.95   Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "#9 25.22 Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "#9 25.25   Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "#9 25.36 Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "#9 25.40   Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "#9 25.55 Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "#9 25.59   Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "#9 25.90 Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "#9 25.93   Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "#9 26.13 Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "#9 26.16   Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "#9 26.24 Collecting python-dateutil<3.0dev,>=2.7.3 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "#9 26.27   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "#9 26.81 Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "#9 26.88   Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "#9 27.32 Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "#9 27.36   Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "#9 28.08 Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "#9 28.12   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "#9 29.82 Collecting pydantic-core==2.27.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "#9 29.85   Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "#9 30.11 Collecting typing-extensions>=4.8.0 (from torch==2.2.0->-r requirements.txt (line 1))\n",
      "#9 30.16   Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "#9 30.71 Collecting charset-normalizer<4,>=2 (from requests->transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 30.77   Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "#9 30.90 Collecting idna<4,>=2.5 (from requests->transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 30.95   Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "#9 31.18 Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 31.23   Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "#9 31.41 Collecting certifi>=2017.4.17 (from requests->transformers==4.38.1->-r requirements.txt (line 2))\n",
      "#9 31.45   Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "#9 32.04 Collecting anyio<5,>=3.4.0 (from starlette<0.42.0,>=0.40.0->fastapi)\n",
      "#9 32.08   Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "#9 32.72 Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->-r requirements.txt (line 1)) (2.1.5)\n",
      "#9 32.92 Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "#9 33.16 Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi)\n",
      "#9 33.20   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "#9 33.30 Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi)\n",
      "#9 33.33   Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "#9 34.37 Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "#9 34.41   Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "#9 34.72 Collecting six>=1.5 (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "#9 34.78   Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "#9 35.28 Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
      "#9 36.48    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.5/8.5 MB 7.2 MB/s eta 0:00:00\n",
      "#9 36.52 Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
      "#9 36.56    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 279.7/279.7 kB 8.0 MB/s eta 0:00:00\n",
      "#9 36.61 Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "#9 36.70    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.9/94.9 kB 1.7 MB/s eta 0:00:00\n",
      "#9 36.75 Downloading google_cloud_aiplatform-1.73.0-py2.py3-none-any.whl (6.3 MB)\n",
      "#9 37.61    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 7.3 MB/s eta 0:00:00\n",
      "#9 37.64 Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "#9 37.65    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 9.8 MB/s eta 0:00:00\n",
      "#9 37.69 Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "#9 37.76 Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "#9 37.85    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.6/156.6 kB 3.0 MB/s eta 0:00:00\n",
      "#9 37.88 Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "#9 37.93    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 kB 6.2 MB/s eta 0:00:00\n",
      "#9 38.00 Downloading google_cloud_bigquery-3.27.0-py2.py3-none-any.whl (240 kB)\n",
      "#9 38.04    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.1/240.1 kB 6.3 MB/s eta 0:00:00\n",
      "#9 38.08 Downloading google_cloud_resource_manager-1.13.1-py2.py3-none-any.whl (358 kB)\n",
      "#9 38.16    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 358.6/358.6 kB 4.5 MB/s eta 0:00:00\n",
      "#9 38.20 Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "#9 38.24    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.5/130.5 kB 79.4 MB/s eta 0:00:00\n",
      "#9 38.27 Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "#9 38.30    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 4.2 MB/s eta 0:00:00\n",
      "#9 38.35 Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "#9 38.44    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.1/442.1 kB 5.0 MB/s eta 0:00:00\n",
      "#9 38.48 Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "#9 38.57    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 447.6/447.6 kB 7.0 MB/s eta 0:00:00\n",
      "#9 38.62 Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "#9 40.87    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.3/16.3 MB 8.0 MB/s eta 0:00:00\n",
      "#9 40.91 Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "#9 40.96    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 3.6 MB/s eta 0:00:00\n",
      "#9 41.02 Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "#9 41.04    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.1/50.1 kB 3.1 MB/s eta 0:00:00\n",
      "#9 41.09 Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "#9 41.17    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.7/319.7 kB 5.9 MB/s eta 0:00:00\n",
      "#9 41.21 Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "#9 41.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 456.4/456.4 kB 6.1 MB/s eta 0:00:00\n",
      "#9 41.35 Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "#9 41.65    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 7.5 MB/s eta 0:00:00\n",
      "#9 41.68 Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "#9 41.72 Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "#9 41.83    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 7.4 MB/s eta 0:00:00\n",
      "#9 41.87 Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "#9 41.98    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 kB 7.5 MB/s eta 0:00:00\n",
      "#9 42.02 Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "#9 42.04    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 kB 5.0 MB/s eta 0:00:00\n",
      "#9 42.07 Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "#9 42.15    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 435.0/435.0 kB 7.0 MB/s eta 0:00:00\n",
      "#9 42.18 Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "#9 42.88    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 3.7 MB/s eta 0:00:00\n",
      "#9 42.92 Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "#9 42.93    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.2/73.2 kB 9.6 MB/s eta 0:00:00\n",
      "#9 42.97 Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "#9 43.48    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 7.1 MB/s eta 0:00:00\n",
      "#9 43.53 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "#9 43.54    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 6.6 MB/s eta 0:00:00\n",
      "#9 43.58 Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "#9 43.62 Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "#9 44.15    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 7.4 MB/s eta 0:00:00\n",
      "#9 44.19 Downloading watchfiles-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "#9 44.27    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.6/442.6 kB 5.5 MB/s eta 0:00:00\n",
      "#9 44.31 Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "#9 44.33    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.2/168.2 kB 10.0 MB/s eta 0:00:00\n",
      "#9 44.36 Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "#9 44.42    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.3/287.3 kB 7.0 MB/s eta 0:00:00\n",
      "#9 44.46 Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "#9 44.48    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 6.8 MB/s eta 0:00:00\n",
      "#9 44.53 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "#9 44.57 Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "#9 44.60    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 4.5 MB/s eta 0:00:00\n",
      "#9 44.63 Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "#9 44.68 Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "#9 44.70    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.3/167.3 kB 10.0 MB/s eta 0:00:00\n",
      "#9 44.74 Downloading charset_normalizer-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "#9 44.76    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 144.8/144.8 kB 12.0 MB/s eta 0:00:00\n",
      "#9 44.80 Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "#9 44.87 Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "#9 44.92 Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "#9 44.94    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 10.7 MB/s eta 0:00:00\n",
      "#9 44.98 Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "#9 45.03    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.7/221.7 kB 8.5 MB/s eta 0:00:00\n",
      "#9 45.06 Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "#9 45.10 Downloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "#9 45.92    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 7.4 MB/s eta 0:00:00\n",
      "#9 45.95 Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "#9 45.98 Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "#9 46.00    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.4/70.4 kB 7.4 MB/s eta 0:00:00\n",
      "#9 46.03 Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "#9 46.07    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.5/181.5 kB 7.3 MB/s eta 0:00:00\n",
      "#9 46.10 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#9 46.16    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 4.7 MB/s eta 0:00:00\n",
      "#9 46.19 Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "#9 46.23 Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "#9 46.25    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.3/126.3 kB 6.7 MB/s eta 0:00:00\n",
      "#9 46.29 Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "#9 46.32 Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "#9 46.34    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.1/83.1 kB 12.9 MB/s eta 0:00:00\n",
      "#9 46.37 Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 46.42 Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "#9 48.88 Installing collected packages: websockets, uvloop, urllib3, typing-extensions, tqdm, sniffio, six, safetensors, regex, pyyaml, python-dotenv, pyasn1, psutil, protobuf, packaging, numpy, idna, httptools, h11, grpcio, google-crc32c, exceptiongroup, docstring-parser, click, charset-normalizer, certifi, cachetools, annotated-types, uvicorn, shapely, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, anyio, watchfiles, starlette, pydantic, huggingface-hub, grpcio-status, google-auth, tokenizers, grpc-google-iam-v1, google-api-core, fastapi, accelerate, transformers, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "#9 49.33   Attempting uninstall: typing-extensions\n",
      "#9 49.33     Found existing installation: typing_extensions 4.9.0\n",
      "#9 49.35     Uninstalling typing_extensions-4.9.0:\n",
      "#9 49.59       Successfully uninstalled typing_extensions-4.9.0\n",
      "#9 82.00 Successfully installed accelerate-0.27.0 annotated-types-0.7.0 anyio-4.6.2.post1 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 docstring-parser-0.16 exceptiongroup-1.2.2 fastapi-0.115.5 google-api-core-2.23.0 google-auth-2.36.0 google-cloud-aiplatform-1.73.0 google-cloud-bigquery-3.27.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.13.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.66.0 grpc-google-iam-v1-0.13.1 grpcio-1.68.0 grpcio-status-1.68.0 h11-0.14.0 httptools-0.6.4 huggingface-hub-0.26.3 idna-3.10 numpy-2.1.3 packaging-24.2 proto-plus-1.25.0 protobuf-5.29.0 psutil-6.1.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.2 pydantic-core-2.27.1 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rsa-4.9 safetensors-0.4.5 shapely-2.0.6 six-1.16.0 sniffio-1.3.1 starlette-0.41.3 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.38.1 typing-extensions-4.12.2 urllib3-2.2.3 uvicorn-0.32.1 uvloop-0.21.0 watchfiles-1.0.0 websockets-14.1\n",
      "#9 82.00 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 82.62 \n",
      "#9 82.62 [notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "#9 82.62 [notice] To update, run: python -m pip install --upgrade pip\n",
      "#9 DONE 84.8s\n",
      "\n",
      "#10 exporting to image\n",
      "#10 exporting layers\n",
      "#10 exporting layers 3.8s done\n",
      "#10 writing image sha256:caac8dbfdcf264c633a9cdb2bfdd3ac2f6191b860d5d6adf8c1487b55f5ff3b6 0.0s done\n",
      "#10 naming to europe-west3-docker.pkg.dev/sign-lang-translator-20241029/dev-vertex-ai-repo/untrained-predictor:latest 0.0s done\n",
      "#10 DONE 3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pushing Docker image...\n",
      "The push refers to repository [europe-west3-docker.pkg.dev/sign-lang-translator-20241029/dev-vertex-ai-repo/untrained-predictor]\n",
      "7ba2e8f8ae1e: Preparing\n",
      "389d4ac4ebd5: Preparing\n",
      "7d8bb2ae266b: Preparing\n",
      "17cf2dcd2e65: Preparing\n",
      "34e017a0c676: Preparing\n",
      "53ec940b113a: Preparing\n",
      "4e2b998b3fee: Preparing\n",
      "7d363b148ad5: Preparing\n",
      "81f7adde8bea: Preparing\n",
      "fa9c963de60f: Preparing\n",
      "25b5af5e3767: Preparing\n",
      "256d88da4185: Preparing\n",
      "7d363b148ad5: Waiting\n",
      "81f7adde8bea: Waiting\n",
      "fa9c963de60f: Waiting\n",
      "4e2b998b3fee: Waiting\n",
      "25b5af5e3767: Waiting\n",
      "256d88da4185: Waiting\n",
      "53ec940b113a: Waiting\n",
      "389d4ac4ebd5: Layer already exists\n",
      "7d8bb2ae266b: Layer already exists\n",
      "17cf2dcd2e65: Layer already exists\n",
      "34e017a0c676: Layer already exists\n",
      "7d363b148ad5: Layer already exists\n",
      "53ec940b113a: Layer already exists\n",
      "81f7adde8bea: Layer already exists\n",
      "4e2b998b3fee: Layer already exists\n",
      "fa9c963de60f: Layer already exists\n",
      "256d88da4185: Layer already exists\n",
      "25b5af5e3767: Layer already exists\n",
      "7ba2e8f8ae1e: Pushed\n",
      "latest: digest: sha256:df69be568d088d9f9ea10ab9f72bbedeb6c752688965caeabdf8d0cde5606b48 size: 2834\n",
      "\n",
      "Container image available at: europe-west3-docker.pkg.dev/sign-lang-translator-20241029/dev-vertex-ai-repo/untrained-predictor:latest\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def build_and_push_image(config):\n",
    "    \"\"\"Build and push the Docker image to Artifact Registry\"\"\"\n",
    "    image_uri = f\"{config['region']}-docker.pkg.dev/{config['project_id']}/{config['artifact_registry_repo']}/{config['image_name']}:latest\"\n",
    "    \n",
    "    # Configure Docker authentication for Artifact Registry\n",
    "    print(\"Configuring Docker authentication...\")\n",
    "    subprocess.run([\n",
    "        \"gcloud\", \"auth\", \"configure-docker\",\n",
    "        f\"{config['region']}-docker.pkg.dev\"\n",
    "    ], check=True)\n",
    "    \n",
    "    # Get paths relative to the project root\n",
    "    docker_path = project_root / \"models\" / \"types\" / \"huggingface\" / \"docker\"\n",
    "\n",
    "    \n",
    "    # Build command\n",
    "    build_cmd = [\n",
    "        \"docker\", \"build\",\n",
    "        \"-t\", image_uri,\n",
    "        \"--build-arg\", f\"HF_TASK={config['hf_task']}\",\n",
    "        \"--platform=linux/amd64\",\n",
    "        \"-f\", str(docker_path / \"Dockerfile\"),\n",
    "        str(docker_path)\n",
    "    ]\n",
    "    \n",
    "    print(\"Building Docker image...\")\n",
    "    subprocess.run(build_cmd, check=True)\n",
    "    \n",
    "    print(\"\\nPushing Docker image...\")\n",
    "    subprocess.run([\"docker\", \"push\", image_uri], check=True)\n",
    "    \n",
    "    return image_uri\n",
    "\n",
    "# Execute\n",
    "container_image_uri = build_and_push_image(config)\n",
    "print(f\"\\nContainer image available at: {container_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deploy to Vertex AI\n",
    "Finally, deploy the model to a Vertex AI endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using artifacts URI: gs://sign-lang-translator-20241029-dev-vertex-ai-artifacts/v1\n",
      "Uploading model to Vertex AI...\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/788230573749/locations/europe-west3/models/3322486644627472384/operations/7468035258215038976\n",
      "Model created. Resource name: projects/788230573749/locations/europe-west3/models/3322486644627472384@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/788230573749/locations/europe-west3/models/3322486644627472384@1')\n",
      "\n",
      "Fetching existing endpoint...\n",
      "\n",
      "Deploying model to endpoint...\n",
      "Deploying model to Endpoint : projects/788230573749/locations/europe-west3/endpoints/dev-vertex-ai-endpoint\n",
      "Deploy Endpoint model backing LRO: projects/788230573749/locations/europe-west3/endpoints/dev-vertex-ai-endpoint/operations/3254917806809939968\n"
     ]
    },
    {
     "ename": "FailedPrecondition",
     "evalue": "400 Model server exited unexpectedly. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=788230573749&resource=aiplatform.googleapis.com%2FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%22dev-vertex-ai-endpoint%22%0Aresource.labels.location%3D%22europe-west3%22. 9: Model server exited unexpectedly. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=788230573749&resource=aiplatform.googleapis.com%2FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%22dev-vertex-ai-endpoint%22%0Aresource.labels.location%3D%22europe-west3%22.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m endpoint\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Execute\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mdeploy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifacts_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontainer_image_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel deployed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;241m.\u001b[39mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m, in \u001b[0;36mdeploy_model\u001b[0;34m(config, artifacts_uri, container_image_uri)\u001b[0m\n\u001b[1;32m     24\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mEndpoint(\n\u001b[1;32m     25\u001b[0m     endpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Fixed string concatenation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     project\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     27\u001b[0m     location\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDeploying model to endpoint...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn1-standard-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:3564\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, enable_access_logging, disable_container_logging)\u001b[0m\n\u001b[1;32m   3553\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraffic splitting is not yet supported for PrivateEndpoint. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry calling deploy() without providing `traffic_split`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA maximum of one model can be deployed to each private Endpoint.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3557\u001b[0m         )\n\u001b[1;32m   3559\u001b[0m explanation_spec \u001b[38;5;241m=\u001b[39m _explanation_utils\u001b[38;5;241m.\u001b[39mcreate_and_validate_explanation_spec(\n\u001b[1;32m   3560\u001b[0m     explanation_metadata\u001b[38;5;241m=\u001b[39mexplanation_metadata,\n\u001b[1;32m   3561\u001b[0m     explanation_parameters\u001b[38;5;241m=\u001b[39mexplanation_parameters,\n\u001b[1;32m   3562\u001b[0m )\n\u001b[0;32m-> 3564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmachine_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplanation_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencryption_spec_key_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencryption_spec_key_name\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencryption_spec_key_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3584\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_access_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_access_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_container_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_container_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:817\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    816\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    820\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:3736\u001b[0m, in \u001b[0;36mModel._deploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_spec, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, enable_access_logging, disable_container_logging)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         endpoint \u001b[38;5;241m=\u001b[39m PrivateEndpoint\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m   3726\u001b[0m             display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[1;32m   3727\u001b[0m             network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3731\u001b[0m             encryption_spec_key_name\u001b[38;5;241m=\u001b[39mencryption_spec_key_name,\n\u001b[1;32m   3732\u001b[0m         )\n\u001b[1;32m   3734\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_start_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploying model to\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoint)\n\u001b[0;32m-> 3736\u001b[0m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deploy_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3739\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployed_model_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraffic_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraffic_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmachine_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_replica_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_replica_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3748\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3749\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplanation_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeploy_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_cpu_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoscaling_target_accelerator_duty_cycle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3756\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_access_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_access_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_container_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_container_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeployed\u001b[39m\u001b[38;5;124m\"\u001b[39m, endpoint)\n\u001b[1;32m   3762\u001b[0m endpoint\u001b[38;5;241m.\u001b[39m_sync_gca_resource()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:1302\u001b[0m, in \u001b[0;36mEndpoint._deploy_call\u001b[0;34m(cls, api_client, endpoint_resource_name, model, endpoint_resource_traffic_split, network, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_spec, metadata, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle, enable_access_logging, disable_container_logging)\u001b[0m\n\u001b[1;32m   1290\u001b[0m operation_future \u001b[38;5;241m=\u001b[39m api_client\u001b[38;5;241m.\u001b[39mdeploy_model(\n\u001b[1;32m   1291\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint_resource_name,\n\u001b[1;32m   1292\u001b[0m     deployed_model\u001b[38;5;241m=\u001b[39mdeployed_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mdeploy_request_timeout,\n\u001b[1;32m   1296\u001b[0m )\n\u001b[1;32m   1298\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m, operation_future\n\u001b[1;32m   1300\u001b[0m )\n\u001b[0;32m-> 1302\u001b[0m \u001b[43moperation_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 Model server exited unexpectedly. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=788230573749&resource=aiplatform.googleapis.com%2FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%22dev-vertex-ai-endpoint%22%0Aresource.labels.location%3D%22europe-west3%22. 9: Model server exited unexpectedly. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=788230573749&resource=aiplatform.googleapis.com%2FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%22dev-vertex-ai-endpoint%22%0Aresource.labels.location%3D%22europe-west3%22."
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# First, verify the exact GCS path\n",
    "artifacts_uri = f\"gs://{config['artifacts_bucket']}/{config['model_version']}\"\n",
    "print(f\"Using artifacts URI: {artifacts_uri}\")\n",
    "\n",
    "# Then deploy using this verified path\n",
    "def deploy_model(config, artifacts_uri, container_image_uri):\n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=config['project_id'], location=config['region'])\n",
    "    \n",
    "    print(\"Uploading model to Vertex AI...\")\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=f\"hf-{config['model_id'].split('/')[-1]}\",\n",
    "        artifact_uri=artifacts_uri,  # This should point to the directory containing model.tar.gz\n",
    "        serving_container_image_uri=container_image_uri,\n",
    "        serving_container_environment_variables={\n",
    "            \"HF_TASK\": config['hf_task'],\n",
    "            \"VERTEX_CPR_WEB_CONCURRENCY\": \"1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFetching existing endpoint...\")\n",
    "    endpoint = aiplatform.Endpoint(\n",
    "        endpoint_name=f\"{config['environment']}-{config['endpoint_name']}-endpoint\",  # Fixed string concatenation\n",
    "        project=config['project_id'],\n",
    "        location=config['region']\n",
    "    )\n",
    "\n",
    "\n",
    "    print(\"\\nDeploying model to endpoint...\")\n",
    "    endpoint = model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1,\n",
    "    )\n",
    "    \n",
    "    return endpoint\n",
    "\n",
    "# Execute\n",
    "endpoint = deploy_model(config, artifacts_uri, container_image_uri)\n",
    "print(f\"\\nModel deployed successfully!\")\n",
    "print(f\"Endpoint: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Endpoint\n",
    "Let's test the deployed model with a sample prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.api import httpbody_pb2\n",
    "\n",
    "def test_prediction(project_id: str, location: str, endpoint_id: str, test_data: dict):\n",
    "    client = aiplatform_v1.PredictionServiceClient(\n",
    "        client_options={\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n",
    "    )\n",
    "    \n",
    "    endpoint = f\"projects/{project_id}/locations/{location}/endpoints/{endpoint_id}\"\n",
    "    \n",
    "    json_data = json.dumps(test_data)\n",
    "    http_body = httpbody_pb2.HttpBody(\n",
    "        data=json_data.encode(\"utf-8\"),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    "    \n",
    "    request = aiplatform_v1.RawPredictRequest(\n",
    "        endpoint=endpoint,\n",
    "        http_body=http_body,\n",
    "    )\n",
    "    \n",
    "    response = client.raw_predict(request)\n",
    "    return json.loads(response.data)\n",
    "\n",
    "# Test data for zero-shot classification\n",
    "test_data = {\n",
    "    \"sequences\": \"I need help with my account login\",\n",
    "    \"candidate_labels\": [\"account access\", \"billing\", \"technical issue\", \"general inquiry\"]\n",
    "}\n",
    "\n",
    "# Get endpoint ID from the endpoint resource name\n",
    "endpoint_id = endpoint.resource_name.split(\"/\")[-1]\n",
    "\n",
    "# Run test prediction\n",
    "result = test_prediction(\n",
    "    config['project_id'],\n",
    "    config['region'],\n",
    "    endpoint_id,\n",
    "    test_data\n",
    ")\n",
    "\n",
    "print(\"Prediction result:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
