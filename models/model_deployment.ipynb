{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing Example\n",
    "This notebook demonstrates how to use the CloudProcessor for batch processing data with single or multiple workers.\n",
    "\n",
    "## 1. Configuration\n",
    "Set the project root path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root detected at: /home/steffen/sign-language-translator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "def setup_project_path():\n",
    "    \"\"\"Add project root to Python path by searching for .git directory\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Search up the directory tree for .git folder or pyproject.toml\n",
    "    root_indicators = ['.git', 'pyproject.toml']\n",
    "    \n",
    "    while current_path != current_path.parent:\n",
    "        if any((current_path / indicator).exists() for indicator in root_indicators):\n",
    "            sys.path.append(str(current_path))\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root. \"\n",
    "        \"Please run this notebook from within the project directory.\"\n",
    "    )\n",
    "\n",
    "# Setup path\n",
    "project_root = setup_project_path()\n",
    "print(f\"Project root detected at: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your vertex ai configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration from /home/steffen/sign-language-translator/models/vertex_ai/config/dev.yaml\n",
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from models.vertex_ai import get_config\n",
    "\n",
    "# Get vertex ai configuration for 'dev' environment\n",
    "config = get_config(\"dev\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Deployment\n",
    "\n",
    "Define the model id and task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_id = \"openai/whisper-small\"\n",
    "hf_task = \"automatic-speech-recognition\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vertex_ai import ModelDeployer\n",
    "# Initialize deployer with your config\n",
    "deployer = ModelDeployer(\n",
    "    project_id=config.project_id,\n",
    "    environment=config.environment\n",
    ")\n",
    "\n",
    "# Trigger the deployment and wait for completion\n",
    "try:\n",
    "    build_info = deployer.trigger_deployment(\n",
    "        model_id=hf_model_id,\n",
    "        hf_task=hf_task,\n",
    "        endpoint_id=\"your-endpoint-id\",  # Add your endpoint ID here\n",
    "        branch=\"steffen74/issue18\",\n",
    "        hf_token=config.huggingface_token,\n",
    "        trigger_name=\"test\",\n",
    "        wait_for_completion=True,  # This will make it wait\n",
    "        timeout_minutes=45  # Adjust based on your expected build time\n",
    "    )\n",
    "    \n",
    "    if build_info['status'] == 'SUCCESS':\n",
    "        print(\"Deployment completed successfully!\")\n",
    "    else:\n",
    "        print(f\"Deployment failed with status: {build_info['status']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during deployment: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interrupt the model deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployer.cancel_deployment(\"<build_id>\") # Add the build id here\n",
    "\n",
    "# The build id is printed at the beginning of the trigger deployment above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
