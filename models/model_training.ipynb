{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Example\n",
    "\n",
    "This notebook demonstrates how to use the `model_trainer` class to submit preprocessing and training jobs to Vertex AI.\n",
    "## 1. Configuration\n",
    "Set the project root path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "def setup_project_path():\n",
    "    \"\"\"Add project root to Python path by searching for .git directory\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Search up the directory tree for .git folder or pyproject.toml\n",
    "    root_indicators = ['.git', 'pyproject.toml']\n",
    "    \n",
    "    while current_path != current_path.parent:\n",
    "        if any((current_path / indicator).exists() for indicator in root_indicators):\n",
    "            sys.path.append(str(current_path))\n",
    "            return current_path\n",
    "        current_path = current_path.parent\n",
    "    \n",
    "    raise RuntimeError(\n",
    "        \"Could not find project root. \"\n",
    "        \"Please run this notebook from within the project directory.\"\n",
    "    )\n",
    "\n",
    "# Setup path\n",
    "project_root = setup_project_path()\n",
    "print(f\"Project root detected at: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your vertex ai configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vertex_ai import get_config\n",
    "\n",
    "# Get vertex ai configuration for 'dev' environment\n",
    "config = get_config(\"dev\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an Experiment\n",
    "First, we import the `ModelTrainer` class and instantiate it.\n",
    "We then create an experiment with a name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vertex_ai import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    environment=\"dev\",\n",
    "    data_bucket=f\"{config.project_id}-{config.environment}-data\",\n",
    ")\n",
    "\n",
    "experiment = trainer.create_experiment(\n",
    "    \"bert-fine-tuning\",\n",
    "    description=\"Fine-tuning BERT for text classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submit a Preprocessing Job\n",
    "\n",
    "Next, we might want to submit a preprocessing job. This job will execute a Python script on Vertex AI. The script should be located in your project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a preprocessing job\n",
    "preprocessing_job = trainer.submit_preprocessing_job(\n",
    "    script_path=\"models/scripts/processing/extract_landmarks.py\",\n",
    "    args={\n",
    "        \"input-folder\": \"raw-data/\",\n",
    "        \"output-folder\": \"landmarks/\",\n",
    "        \"batch-size\": 32\n",
    "    },\n",
    "    sync=True # Set to False if you don't want to wait for the job to complete\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Model\n",
    "\n",
    "Finally, we submit a training job. This job will also execute a Python script on Vertex AI. The script should be compatible with the requirements specified in the `submit_training_job` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular training with experiment tracking\n",
    "trainer.submit_training_job(\n",
    "    script_path=\"train.py\",\n",
    "    args={\n",
    "        \"data-folder\": \"training/\",\n",
    "        \"model-folder\": \"models/\",\n",
    "        \"learning_rate\": 1e-4\n",
    "    },\n",
    "    experiment_name=\"whisper-fine-tuning\",\n",
    "    run_name=\"run-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use hyperparameter tuning to find the best parameters for our model using the `submit_hyperparameter_tuning_job` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "trainer.submit_hyperparameter_tuning_job(\n",
    "    script_path=\"train.py\",\n",
    "    metric_id=\"accuracy\",\n",
    "    parameter_specs={\n",
    "        \"learning_rate\": {\"min\": 1e-5, \"max\": 1e-3, \"scale\": \"log\"},\n",
    "        \"batch_size\": {\"min\": 16, \"max\": 128, \"scale\": \"linear\"}\n",
    "    },\n",
    "    max_trials=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
