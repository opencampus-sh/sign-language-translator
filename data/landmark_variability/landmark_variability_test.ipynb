{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5478cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def cut_video_ffmpeg(input_video_path, output_video_path, start_time, duration):\n",
    "    \"\"\"\n",
    "    Cut video using FFmpeg (fastest method)\n",
    "    \n",
    "    Args:\n",
    "        input_video_path: Path to input video\n",
    "        output_video_path: Path to output video\n",
    "        start_time: Start time in seconds (e.g., 30.5) or \"MM:SS\" format (e.g., \"01:30\")\n",
    "        duration: Duration in seconds (e.g., 20) or \"MM:SS\" format (e.g., \"00:20\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to string format if needed\n",
    "        if isinstance(start_time, (int, float)):\n",
    "            start_str = str(start_time)\n",
    "        else:\n",
    "            start_str = start_time\n",
    "            \n",
    "        if isinstance(duration, (int, float)):\n",
    "            duration_str = str(duration)\n",
    "        else:\n",
    "            duration_str = duration\n",
    "            \n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-y',  # Overwrite output file\n",
    "            '-i', input_video_path,\n",
    "            '-ss', start_str,  # Start time\n",
    "            '-t', duration_str,  # Duration\n",
    "            '-c', 'copy',  # Copy streams without re-encoding (fastest)\n",
    "            output_video_path\n",
    "        ]\n",
    "        \n",
    "        print(f\"Cutting video from {start_str}s for {duration_str}s...\")\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Video cut successfully: {output_video_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error cutting video: {e}\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a08a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess\n",
    "# import os\n",
    "# from mediapipe.framework.formats import landmark_pb2\n",
    "import statistics\n",
    "# import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================================================\n",
    "# LANDMARK DETECTION VARIABILITY TESTING FOR THE HANDS\n",
    "# ============================================================================\n",
    "\n",
    "def test_landmark_variability_hands(video_path, num_iterations=5, output_report_path=\"variability_report_hands.json\"):\n",
    "    \"\"\"\n",
    "    Test variability of landmark detection by running the same video multiple times\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        num_iterations: Number of times to run landmark detection\n",
    "        output_report_path: Path to save the variability report\n",
    "    \"\"\"\n",
    "    print(f\"Testing landmark detection variability with {num_iterations} iterations...\")\n",
    "    \n",
    "    # Initialize MediaPipe\n",
    "    mp_hands = mp.solutions.hands\n",
    "    # mp_drawing = mp.solutions.drawing_utils\n",
    "    \n",
    "    # Store results from all iterations\n",
    "    all_iterations_data = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"\\n--- Iteration {iteration + 1}/{num_iterations} ---\")\n",
    "        \n",
    "        # Initialize video capture\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video: {video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        # fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        # height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Calculate right half coordinates\n",
    "        right_half_width = width // 2\n",
    "        start_x = width - right_half_width\n",
    "        \n",
    "        # Store landmarks for this iteration\n",
    "        iteration_data = {\n",
    "            \"iteration\": iteration + 1,\n",
    "            \"frames\": []\n",
    "        }\n",
    "        \n",
    "        with mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        ) as hands:\n",
    "            \n",
    "            frame_idx = 0\n",
    "            while cap.isOpened():\n",
    "                ret, frame_bgr = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Process only right half\n",
    "                right_half_frame = frame_bgr[:, start_x:width]\n",
    "                image = cv2.cvtColor(right_half_frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "                \n",
    "                # Detect hands\n",
    "                results = hands.process(image)\n",
    "                \n",
    "                # Store frame data\n",
    "                frame_data = {\n",
    "                    \"frame\": frame_idx,\n",
    "                    \"hands\": []\n",
    "                }\n",
    "                \n",
    "                if results.multi_hand_landmarks and results.multi_handedness:\n",
    "                    for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "                        hand_label = handedness.classification[0].label\n",
    "                        \n",
    "                        # Extract landmarks\n",
    "                        landmarks = []\n",
    "                        for lm in hand_landmarks.landmark:\n",
    "                            landmarks.append({\n",
    "                                \"x\": lm.x,\n",
    "                                \"y\": lm.y,\n",
    "                                \"z\": lm.z\n",
    "                            })\n",
    "                        \n",
    "                        frame_data[\"hands\"].append({\n",
    "                            \"label\": hand_label,\n",
    "                            \"landmarks\": landmarks\n",
    "                        })\n",
    "                \n",
    "                iteration_data[\"frames\"].append(frame_data)\n",
    "                frame_idx += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if frame_idx % 50 == 0:\n",
    "                    print(f\"Processed {frame_idx}/{frame_count} frames\")\n",
    "        \n",
    "        cap.release()\n",
    "        all_iterations_data.append(iteration_data)\n",
    "        print(f\"Iteration {iteration + 1} completed: {frame_idx} frames processed\")\n",
    "    \n",
    "    # Analyze variability\n",
    "    variability_stats = analyze_landmark_variability(all_iterations_data)\n",
    "    \n",
    "    # Save complete report\n",
    "    report = {\n",
    "        \"metadata\": {\n",
    "            \"video_path\": video_path,\n",
    "            \"num_iterations\": num_iterations,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        },\n",
    "        \"raw_data\": all_iterations_data,\n",
    "        \"variability_analysis\": variability_stats\n",
    "    }\n",
    "    \n",
    "    with open(output_report_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    # print(f\"\\nVariability test completed!\")\n",
    "    print(f\"Report saved to: {output_report_path}\")\n",
    "    print(\"\\nVariability Summary:\")\n",
    "    print(f\"Average detection rate: {variability_stats['detection_rate_stats']['mean']:.2f}%\")\n",
    "    print(f\"Detection consistency (std): {variability_stats['detection_rate_stats']['std']:.2f}%\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "def analyze_landmark_variability(all_iterations_data):\n",
    "    \"\"\"\n",
    "    Analyze variability statistics from multiple iterations\n",
    "    \"\"\"\n",
    "    # print(\"\\nAnalyzing landmark variability...\")\n",
    "    \n",
    "    # Calculate detection rates for each iteration\n",
    "    detection_rates = []\n",
    "    total_frames = len(all_iterations_data[0][\"frames\"]) if all_iterations_data else 0\n",
    "    \n",
    "    for iteration_data in all_iterations_data:\n",
    "        frames_with_hands = sum(1 for frame in iteration_data[\"frames\"] if frame[\"hands\"])\n",
    "        detection_rate = (frames_with_hands / total_frames) * 100 if total_frames > 0 else 0\n",
    "        detection_rates.append(detection_rate)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        \"detection_rate_stats\": {\n",
    "            \"mean\": np.round(statistics.mean(detection_rates), 2) if detection_rates else 0,\n",
    "            \"std\": np.round(statistics.stdev(detection_rates), 2) if len(detection_rates) > 1 else 0,\n",
    "            \"min\": np.round(min(detection_rates), 2) if detection_rates else 0,\n",
    "            \"max\": np.round(max(detection_rates),2) if detection_rates else 0,\n",
    "            \"rates_per_iteration\": detection_rates\n",
    "        },\n",
    "        \"landmark_position_variability\": calculate_landmark_position_variability(all_iterations_data)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def calculate_landmark_position_variability(all_iterations_data):\n",
    "    \"\"\"\n",
    "    Calculate variability in landmark positions across iterations\n",
    "    \"\"\"\n",
    "    if not all_iterations_data:\n",
    "        return {}\n",
    "    \n",
    "    # Group landmarks by frame and landmark point\n",
    "    frame_landmark_positions = {}\n",
    "    \n",
    "    for iteration_data in all_iterations_data:\n",
    "        for frame_data in iteration_data[\"frames\"]:\n",
    "            frame_idx = frame_data[\"frame\"]\n",
    "            \n",
    "            if frame_idx not in frame_landmark_positions:\n",
    "                frame_landmark_positions[frame_idx] = {}\n",
    "            \n",
    "            for hand_data in frame_data[\"hands\"]:\n",
    "                hand_key = f\"{hand_data['label']}_hand\"\n",
    "                \n",
    "                if hand_key not in frame_landmark_positions[frame_idx]:\n",
    "                    frame_landmark_positions[frame_idx][hand_key] = {i: [] for i in range(21)}  # 21 landmarks per hand\n",
    "                \n",
    "                for lm_idx, landmark in enumerate(hand_data[\"landmarks\"]):\n",
    "                    frame_landmark_positions[frame_idx][hand_key][lm_idx].append([\n",
    "                        landmark[\"x\"], landmark[\"y\"], landmark[\"z\"]\n",
    "                    ])\n",
    "    \n",
    "    # Calculate variability statistics\n",
    "    variability_stats = {}\n",
    "    \n",
    "    # NEW: Create lists to hold the std for each coordinate separately\n",
    "    all_stds_x = []\n",
    "    all_stds_y = []\n",
    "    all_stds_z = []\n",
    "    \n",
    "    all_stds = []\n",
    "    for frame_idx, frame_data in frame_landmark_positions.items():\n",
    "        for hand_key, landmarks in frame_data.items():\n",
    "            for lm_idx, positions in landmarks.items():\n",
    "                if len(positions) > 1:  # Need at least 2 positions to calculate std\n",
    "                    positions_array = np.array(positions)\n",
    "                    std_per_coord = np.std(positions_array, axis=0)\n",
    "                    all_stds_x.append(std_per_coord[0]) # std for x\n",
    "                    all_stds_y.append(std_per_coord[1]) # std for y\n",
    "                    all_stds_z.append(std_per_coord[2]) # std for z\n",
    "                    # avg_std = np.mean(std_per_coord)\n",
    "                    # all_stds.append(avg_std)\n",
    "    \n",
    "    if all_stds_x: # If we have data\n",
    "        # Calculate and store the average and max std for each coordinate\n",
    "        variability_stats[\"average_std\"] = {\n",
    "            \"x\": np.round(statistics.mean(all_stds_x), 4),\n",
    "            \"y\": np.round(statistics.mean(all_stds_y), 4),\n",
    "            \"z\": np.round(statistics.mean(all_stds_z), 4)\n",
    "        }\n",
    "        variability_stats[\"max_std\"] = {\n",
    "            \"x\": np.round(max(all_stds_x), 4),\n",
    "            \"y\": np.round(max(all_stds_y), 4),\n",
    "            \"z\": np.round(max(all_stds_z), 4)\n",
    "        }\n",
    "\n",
    "    return variability_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VIDEO PROCESSING SUITE ===\n",
      "\n",
      "Step 1: Cutting video...\n",
      "Cutting video from 44s for 10s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video cut successfully: short_video_10sec.mp4\n",
      "Testing landmark detection variability with 3 iterations...\n",
      "\n",
      "--- Iteration 1/3 ---\n",
      "Processed 50/202 frames\n",
      "Processed 100/202 frames\n",
      "Processed 150/202 frames\n",
      "Processed 200/202 frames\n",
      "Iteration 1 completed: 202 frames processed\n",
      "\n",
      "--- Iteration 2/3 ---\n",
      "Processed 50/202 frames\n",
      "Processed 100/202 frames\n",
      "Processed 150/202 frames\n",
      "Processed 200/202 frames\n",
      "Iteration 2 completed: 202 frames processed\n",
      "\n",
      "--- Iteration 3/3 ---\n",
      "Processed 50/202 frames\n",
      "Processed 100/202 frames\n",
      "Processed 150/202 frames\n",
      "Processed 200/202 frames\n",
      "Iteration 3 completed: 202 frames processed\n",
      "Report saved to: landmark_variability_report.json\n",
      "\n",
      "Variability Summary:\n",
      "Average detection rate: 100.00%\n",
      "Detection consistency (std): 0.00%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example video path\n",
    "    input_video = \"TV-20241029-2025-3400.webxxl.h264.mp4\"\n",
    "    \n",
    "    print(\"=== VIDEO PROCESSING SUITE ===\\n\")\n",
    "    \n",
    "    # Step 1: Cut video to 20 seconds\n",
    "    print(\"Step 1: Cutting video...\")\n",
    "    short_video = f\"short_video_{10}sec.mp4\"\n",
    "    cut_video_ffmpeg(input_video, short_video, start_time=44, duration=10)    \n",
    "\n",
    "    variability_report_hands = test_landmark_variability_hands(\n",
    "        short_video, \n",
    "        num_iterations=3,  # Adjust as needed\n",
    "        output_report_path=\"landmark_variability_report.json\"\n",
    "    )\n",
    "       \n",
    "    print(\"\\n=== ALL PROCESSING COMPLETED ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
