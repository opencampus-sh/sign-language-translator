{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "import re\n",
    "import json\n",
    "\n",
    "df = pd.read_parquet(\"TV-20250105-2032-2400.webm.h264.mp4_filtered.parquet\", engine=\"pyarrow\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TV-20250105-2032-2400.webm.h264.mp4.json\", \"r\") as f:\n",
    "    transcript = json.load(f)\n",
    "\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Tagesschau Intro\n",
    "transcript_without_intro = transcript[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(transcripts, fps=25, frame_window=750):\n",
    "    \"\"\"\n",
    "    Process video transcripts to find text segments and associated words within a frame window.\n",
    "    Each result contains all complete sentences that fit within the frame window.\n",
    "    \n",
    "    Args:\n",
    "        transcripts (list): List of transcript dictionaries\n",
    "        fps (int): Frames per second of the video\n",
    "        frame_window (int): Number of frames to look ahead\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing segment text and all segments within frame window\n",
    "    \"\"\"\n",
    "    # Convert frame window to seconds\n",
    "    time_window = frame_window / fps\n",
    "    results = []\n",
    "    \n",
    "    # Helper function to check if text starts a sentence\n",
    "    def is_sentence_start(text):\n",
    "        # Strip leading whitespace and check if first char is uppercase\n",
    "        cleaned_text = text.lstrip()\n",
    "        return bool(cleaned_text and cleaned_text[0].isupper())\n",
    "    \n",
    "    # Helper function to check if text ends a sentence\n",
    "    def is_sentence_end(text):\n",
    "        # Check if text ends with common sentence endings\n",
    "        return bool(re.search(r'[.!?]\\s*$', text))\n",
    "    \n",
    "    for i, transcript in enumerate(transcripts):\n",
    "        segment_start = transcript['start']\n",
    "        start_frame = math.floor(segment_start * fps)\n",
    "        window_end_time = segment_start + time_window\n",
    "        \n",
    "        # Skip if this segment doesn't start a sentence and isn't the first segment\n",
    "        if i > 0 and not is_sentence_start(transcript['text']):\n",
    "            continue\n",
    "            \n",
    "        # Collect all segments that fall within this window\n",
    "        segments_in_window = []\n",
    "        current_text = []\n",
    "        current_sentence = []\n",
    "        \n",
    "        # Look at all segments including and after the current one\n",
    "        for next_transcript in transcripts[i:]:\n",
    "            # Skip segments that start after our window\n",
    "            if next_transcript['start'] > window_end_time:\n",
    "                # If we have a partial sentence when we hit the window boundary,\n",
    "                # remove it from the collections\n",
    "                if current_sentence and not is_sentence_end(current_sentence[-1]):\n",
    "                    segments_in_window = segments_in_window[:-(len(current_sentence))]\n",
    "                    current_text = current_text[:-(len(current_sentence))]\n",
    "                break\n",
    "                \n",
    "            # Add segment to current sentence collection\n",
    "            current_sentence.append(next_transcript['text'])\n",
    "            \n",
    "            # If we hit the end of a sentence\n",
    "            if is_sentence_end(next_transcript['text']):\n",
    "                # Add all segments from the complete sentence\n",
    "                segments_in_window.extend([{\n",
    "                    'time': next_transcript['start'],\n",
    "                    'text': text\n",
    "                } for text in current_sentence])\n",
    "                current_text.extend(current_sentence)\n",
    "                # Reset current sentence collection\n",
    "                current_sentence = []\n",
    "        \n",
    "        # Only create result if we have complete sentences\n",
    "        if segments_in_window:\n",
    "            result = {\n",
    "                'start_frame': start_frame,\n",
    "                'segment_start_time': segment_start,\n",
    "                'window_end_time': window_end_time,\n",
    "                'original_segment_text': transcript['text'],\n",
    "                'all_segments': segments_in_window,\n",
    "                'combined_text': ' '.join(current_text)\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts_fixed_windows(transcripts, fps=25, frame_window=750):\n",
    "    \"\"\"\n",
    "    Process video transcripts by splitting them into fixed frame windows.\n",
    "    Each window contains all words that appear within that frame range.\n",
    "    \n",
    "    Args:\n",
    "        transcripts (list): List of transcript dictionaries\n",
    "        fps (int): Frames per second of the video\n",
    "        frame_window (int): Size of each frame window\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing all segments within each frame window\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Find the last timestamp to determine total number of windows needed\n",
    "    max_time = max(transcript['start'] for transcript in transcripts)\n",
    "    max_frame = int(max_time * fps)\n",
    "    \n",
    "    # Calculate number of full windows needed\n",
    "    num_windows = (max_frame // frame_window) + 1\n",
    "    \n",
    "    for window_idx in range(num_windows):\n",
    "        # Calculate window boundaries in frames\n",
    "        start_frame = window_idx * frame_window\n",
    "        end_frame = start_frame + frame_window - 1  # -1 because frames are 0-indexed\n",
    "        \n",
    "        # Convert to timestamps\n",
    "        start_time = start_frame / fps\n",
    "        end_time = (end_frame + 1) / fps  # +1 to include the full last frame\n",
    "        \n",
    "        # Collect all segments that fall within this window\n",
    "        segments_in_window = []\n",
    "        current_text = []\n",
    "        \n",
    "        for transcript in transcripts:\n",
    "            segment_time = transcript['start']\n",
    "            \n",
    "            # Skip segments before this window\n",
    "            if segment_time < start_time:\n",
    "                continue\n",
    "                \n",
    "            # Stop if we've gone beyond this window\n",
    "            if segment_time >= end_time:\n",
    "                break\n",
    "                \n",
    "            segments_in_window.append({\n",
    "                'time': segment_time,\n",
    "                'text': transcript['text']\n",
    "            })\n",
    "            current_text.append(transcript['text'])\n",
    "        \n",
    "        # Only create result if we have segments in this window\n",
    "        if segments_in_window:\n",
    "            result = {\n",
    "                'start_frame': start_frame,\n",
    "                'end_frame': end_frame,\n",
    "                'window_start_time': start_time,\n",
    "                'window_end_time': end_time,\n",
    "                'all_segments': segments_in_window,\n",
    "                'combined_text': ' '.join(current_text)\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_transcript = process_transcripts(transcript_without_intro)\n",
    "processed_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_transcript = process_transcripts_fixed_windows(transcript_without_intro)\n",
    "processed_transcript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
